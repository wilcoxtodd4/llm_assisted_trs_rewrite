{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af199d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ee61f",
   "metadata": {},
   "source": [
    "### Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e73bfeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = r\"C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\"\n",
    "PLAYERS_JSON = os.path.join(MAIN_DIR, \"players.json\")\n",
    "GIRLS_PLAYERS_CSV = os.path.join(MAIN_DIR, \"girls_players.csv\")\n",
    "SCHOOLS_CSV = os.path.join(MAIN_DIR, \"schools.csv\")\n",
    "\n",
    "PLAYERS_URL = \"https://api.v2.tennisreporting.com/players\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd9b3f",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad27191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Helpers\n",
    "# --------------------------------------------------\n",
    "\n",
    "def clean_lastname(name: str) -> str:\n",
    "    \"\"\"Clean last names like '\\\"Lastname,\\\"' → 'Lastname'.\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    s = str(name).strip()\n",
    "    # Remove surrounding quotes\n",
    "    s = s.strip('\"\\'')\n",
    "    # Remove trailing commas\n",
    "    s = s.rstrip(',')\n",
    "    return s\n",
    "\n",
    "\n",
    "def can_encode_utf8(value) -> bool:\n",
    "    \"\"\"Return False if the value cannot be encoded as UTF-8.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    try:\n",
    "        str(value).encode(\"utf-8\")\n",
    "        return True\n",
    "    except UnicodeEncodeError:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8197748",
   "metadata": {},
   "source": [
    "### Extract player data from tennisreporting.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b82972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading player data...\n",
      "Writing JSON to C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\players.json ...\n"
     ]
    }
   ],
   "source": [
    "# Fetch players JSON and store as players.json\n",
    "print(\"Downloading player data...\")\n",
    "resp = requests.get(PLAYERS_URL)\n",
    "resp.raise_for_status()\n",
    "players_data = resp.json()\n",
    "\n",
    "print(f\"Writing JSON to {PLAYERS_JSON} ...\")\n",
    "with open(PLAYERS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(players_data, f, ensure_ascii=False, indent=2)\n",
    "print(\"JSON file complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a26f3",
   "metadata": {},
   "source": [
    "### Transform and Load to girls_players.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b2b22b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading players.json into DataFrame...\n",
      "Reading schools from C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\schools.csv ...\n",
      "Cleaning lastName values...\n",
      "Stripping whitespace from firstName and lastName...\n",
      "Creating fullname field...\n",
      "Filtered on schoolId in schools.csv: 139612 -> 9614 rows\n",
      "Filtered on genderId == 2: 9614 -> 5365 rows\n",
      "Excluded Default/Default names: 5365 -> 5341 rows\n",
      "Filtered on graduatedDate (exclude < 2025): 5341 -> 2928 rows\n",
      "Selecting and renaming columns for girls_players.csv...\n",
      "Transform and Load Complete\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# Main ETL\n",
    "# --------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    # 1) Read JSON into DataFrame\n",
    "    print(\"Reading players.json into DataFrame...\")\n",
    "    with open(PLAYERS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # 2) Load schools.csv and get valid schoolIDs\n",
    "    print(f\"Reading schools from {SCHOOLS_CSV} ...\")\n",
    "    schools = pd.read_csv(SCHOOLS_CSV, dtype={\"SchoolID\": \"Int64\"})\n",
    "    valid_school_ids = set(schools[\"SchoolID\"].dropna().astype(int))\n",
    "\n",
    "    # 3) Clean last names\n",
    "    print(\"Cleaning lastName values...\")\n",
    "    df[\"lastName\"] = df[\"lastName\"].apply(clean_lastname)\n",
    "    \n",
    "    # 4) Clean leading/trailing whitespace from firstName and lastName\n",
    "    print(\"Stripping whitespace from firstName and lastName...\")\n",
    "    df[\"firstName\"] = df[\"firstName\"].astype(str).str.strip()\n",
    "    df[\"lastName\"]  = df[\"lastName\"].astype(str).str.strip()\n",
    "\n",
    "    # 5) Create fullname = firstname + ' ' + lastname\n",
    "    print(\"Creating fullname field...\")\n",
    "    df[\"fullName\"] = df[\"firstName\"].fillna(\"\").str.strip() + \" \" + df[\"lastName\"].fillna(\"\").str.strip()\n",
    "    df[\"fullName\"] = df[\"fullName\"].str.strip()\n",
    "\n",
    "    # 6) Filtering according to rules\n",
    "\n",
    "    # 6.1) Only include players whose schoolId is present in schools.csv\n",
    "    before = len(df)\n",
    "    df = df[df[\"schoolId\"].isin(valid_school_ids)]\n",
    "    print(f\"Filtered on schoolId in schools.csv: {before} -> {len(df)} rows\")\n",
    "\n",
    "    # 6.2) Only include records where genderId = 2\n",
    "    before = len(df)\n",
    "    df = df[df[\"genderId\"] == 2]\n",
    "    print(f\"Filtered on genderId == 2: {before} -> {len(df)} rows\")\n",
    "\n",
    "    # 6.3) Exclude records where firstname=Default and lastname=Default\n",
    "    before = len(df)\n",
    "    mask_default = (df[\"firstName\"] == \"Default\") & (df[\"lastName\"] == \"Default\")\n",
    "    df = df[~mask_default]\n",
    "    print(f\"Excluded Default/Default names: {before} -> {len(df)} rows\")\n",
    "\n",
    "    # 6.4) Exclude records where graduatedDate is NOT null and year < 2025\n",
    "    #      Keep rows where graduatedDate is null OR year >= 2025\n",
    "    before = len(df)\n",
    "    grad_dates = pd.to_datetime(df[\"graduatedDate\"], errors=\"coerce\", utc=True)\n",
    "    keep_mask = grad_dates.isna() | (grad_dates.dt.year >= 2025)\n",
    "    df = df[keep_mask]\n",
    "    print(f\"Filtered on graduatedDate (exclude < 2025): {before} -> {len(df)} rows\")\n",
    "\n",
    "    # 7) Select and rename columns for output CSV\n",
    "    #    Only keep: id, schoolID, firstname, lastname, grade, fullname\n",
    "    print(\"Selecting and renaming columns for girls_players.csv...\")\n",
    "    df_out = df[[\"id\", \"schoolId\", \"firstName\", \"lastName\", \"grade\", \"fullName\"]].copy()\n",
    "    df_out = df_out.rename(\n",
    "        columns={\n",
    "            \"id\": \"playerID\",\n",
    "            \"schoolId\": \"schoolID\",\n",
    "            \"firstName\": \"firstname\",\n",
    "            \"lastName\": \"lastname\",\n",
    "            \"fullName\": \"fullname\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 8) Write girls_players.csv\n",
    "    print(f\"Writing {GIRLS_PLAYERS_CSV} ...\")\n",
    "    df_out.to_csv(GIRLS_PLAYERS_CSV, index=False, encoding=\"utf-8\")\n",
    "    print(\"girls_players.csv written successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "print(\"Transform and Load Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcaf96a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 10 RECORDS ===\n",
      " playerID  schoolID firstname   lastname     grade          fullname\n",
      "    80635   75619.0     Halle    Shearer Graduated     Halle Shearer\n",
      "    80636   75619.0    Hannah    Millkey Graduated    Hannah Millkey\n",
      "    81005   74665.0    Sophie     Qualls Graduated     Sophie Qualls\n",
      "    81697   75554.0    Sidrah    Schramm        12    Sidrah Schramm\n",
      "    98157   75744.0    Hailey      Foley Graduated      Hailey Foley\n",
      "    98158   75744.0     Vicky     Nguyen Graduated      Vicky Nguyen\n",
      "    98682   75550.0     Maddy    Naugler Graduated     Maddy Naugler\n",
      "    99025   74728.0    Isabel Cunningham Graduated Isabel Cunningham\n",
      "    99026   74728.0    Olivia     Jacoby Graduated     Olivia Jacoby\n",
      "    99031   74614.0     Laina     Atiyeh Graduated      Laina Atiyeh\n",
      "\n",
      "=== LAST 10 RECORDS ===\n",
      " playerID  schoolID firstname lastname     grade        fullname\n",
      "   172901   75129.0     Keely    Burns        10     Keely Burns\n",
      "   172920   75448.0     Eleem     Reta Graduated      Eleem Reta\n",
      "   172921   75448.0     Eleem     Reta Graduated      Eleem Reta\n",
      "   172922   75448.0     Eleem     Reta Graduated      Eleem Reta\n",
      "   172923   75448.0     Eleem     Reta Graduated      Eleem Reta\n",
      "   172927   75619.0 Apollonia    Munoz        11 Apollonia Munoz\n",
      "   172987   75585.0   Delaini    Brown Graduated   Delaini Brown\n",
      "   173014   75880.0     Sofia   Chacon        10    Sofia Chacon\n",
      "   173062   75359.0      True   Dailey        12     True Dailey\n",
      "   173128   74671.0         X  Navarro Graduated       X Navarro\n"
     ]
    }
   ],
   "source": [
    "# --- Read CSV ---\n",
    "df = pd.read_csv(GIRLS_PLAYERS_CSV)\n",
    "\n",
    "# --- Print first 10 records ---\n",
    "print(\"\\n=== TOP 10 RECORDS ===\")\n",
    "print(df.head(10).to_string(index=False))\n",
    "\n",
    "# --- Print last 10 records ---\n",
    "print(\"\\n=== LAST 10 RECORDS ===\")\n",
    "print(df.tail(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8e030",
   "metadata": {},
   "source": [
    "### Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8216eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== DATA QUALITY CHECKS =====\n",
      "\n",
      "Reading CSV: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\girls_players.csv\n",
      "Loaded 2928 rows.\n",
      "\n",
      "Checking for duplicate values...\n",
      "\n",
      "✅ No duplicates in 'playerID'\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Checking for null values...\n",
      "\n",
      "✅ No null values in 'playerID'\n",
      "✅ No null values in 'firstname'\n",
      "✅ No null values in 'lastname'\n",
      "✅ No null values in 'fullname'\n",
      "✅ No null values in 'schoolID'\n",
      "✅ No null values in 'grade'\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Checking for leading/trailing whitespace...\n",
      "\n",
      "⚠️ Field 'playerID' is not a string. Cannot check whitespace.\n",
      "✅ No leading/trailing whitespace in 'firstname'\n",
      "✅ No leading/trailing whitespace in 'lastname'\n",
      "✅ No leading/trailing whitespace in 'fullname'\n",
      "⚠️ Field 'schoolID' is not a string. Cannot check whitespace.\n",
      "✅ No leading/trailing whitespace in 'grade'\n",
      "\n",
      "===== DATA QUALITY CHECK COMPLETE =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from function_scripts.data_quality import check_csv\n",
    "\n",
    "results = check_csv(\n",
    "    csv_path=GIRLS_PLAYERS_CSV,\n",
    "    unique_fields=[\"playerID\"],         \n",
    "    null_fields=[\"playerID\",\"firstname\",\"lastname\",\"fullname\", \"schoolID\",\"grade\"],\n",
    "    whitespace_fields=[\"firstname\",\"lastname\",\"fullname\",\"grade\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8b155",
   "metadata": {},
   "source": [
    "### Custom Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df0e90fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DATA QUALITY CHECKS ---\n",
      "\n",
      "2) Firstnames with non-alphabetic characters:\n",
      "   Alexa G.\n",
      "   Alijah (Jordan)\n",
      "   Ana Rocio (Rosie)\n",
      "   Asha B.\n",
      "   Azul. N\n",
      "   Carolina (Zoe)\n",
      "   Eden (Alex)\n",
      "   Elena (Sophia)\n",
      "   Han (Hana)\n",
      "   Ina M.\n",
      "   Jamie. M\n",
      "   Jenna-Rose\n",
      "   Jenny. G\n",
      "   Katherine (Katy)\n",
      "   Kaydence. EF\n",
      "   Maylanie (Lani)\n",
      "   Maëlys\n",
      "   Nicole (Nikki)\n",
      "   Quetzalli. C\n",
      "   Rissa-Unique\n",
      "   Samatha`\n",
      "   Ta'Resia\n",
      "   Yoselin. Y\n",
      "   default2\n",
      "\n",
      "3) Lastnames with non-alphabetic characters:\n",
      "   .Lambourne\n",
      "   Castañon\n",
      "   O'Connell\n",
      "   Saldaña\n",
      "   Shepard (Barry)\n",
      "   St. Amand\n",
      "   St. Aubin\n",
      "   St.Clair\n",
      "   Zamora Hernández\n",
      "   default2\n",
      "\n",
      "4) Checking for UTF-8 encoding issues...\n",
      "   No UTF-8 encoding problems detected.\n",
      "\n",
      "5) Top 5 most common firstnames:\n",
      "firstname\n",
      "Olivia      32\n",
      "Sophia      28\n",
      "Emily       24\n",
      "Ella        24\n",
      "Isabella    24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create the dataframe\n",
    "df_out = pd.read_csv(GIRLS_PLAYERS_CSV)\n",
    "\n",
    "print(\"\\n--- CUSTOM DATA QUALITY CHECKS ---\")\n",
    "\n",
    "# 1) Show all firstname values that have non-alphabetic characters (excluding spaces)\n",
    "#    (A-Z or a-z only)\n",
    "fname_nonalpha_mask = df_out[\"firstname\"].astype(str).str.contains(r\"[^A-Za-z ]\", na=False)\n",
    "bad_firstnames = df_out.loc[fname_nonalpha_mask, \"firstname\"].dropna().unique()\n",
    "print(\"\\n2) Firstnames with non-alphabetic characters:\")\n",
    "if len(bad_firstnames) == 0:\n",
    "    print(\"   None found.\")\n",
    "else:\n",
    "    for name in sorted(bad_firstnames):\n",
    "        print(\"  \", name)\n",
    "\n",
    "# 2) Show all lastname values that have non-alphabetic characters (excluding spaces and hyphens)\n",
    "lname_nonalpha_mask = df_out[\"lastname\"].astype(str).str.contains(r\"[^A-Za-z -]\", na=False)\n",
    "bad_lastnames = df_out.loc[lname_nonalpha_mask, \"lastname\"].dropna().unique()\n",
    "print(\"\\n3) Lastnames with non-alphabetic characters:\")\n",
    "if len(bad_lastnames) == 0:\n",
    "    print(\"   None found.\")\n",
    "else:\n",
    "    for name in sorted(bad_lastnames):\n",
    "        print(\"  \", name)\n",
    "\n",
    "# 3) Check for values that will cause utf-8 encoding problems\n",
    "print(\"\\n4) Checking for UTF-8 encoding issues...\")\n",
    "problem_cells = []\n",
    "for col in df_out.columns:\n",
    "    if df_out[col].dtype == \"object\":\n",
    "        for idx, val in df_out[col].items():\n",
    "            if not can_encode_utf8(val):\n",
    "                problem_cells.append((idx, col, repr(val)))\n",
    "\n",
    "if not problem_cells:\n",
    "    print(\"   No UTF-8 encoding problems detected.\")\n",
    "else:\n",
    "    print(\"   Potential UTF-8 encoding problems found in the following cells:\")\n",
    "    for idx, col, val_repr in problem_cells:\n",
    "        print(f\"   Row {idx}, Column {col}, Value {val_repr}\")\n",
    "\n",
    "# 4) Frequency report on first name and show 5 most common\n",
    "print(\"\\n5) Top 5 most common firstnames:\")\n",
    "freq_first = df_out[\"firstname\"].value_counts().head(5)\n",
    "print(freq_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05dbb0",
   "metadata": {},
   "source": [
    "### Identify players with multiple IDs (same first and last name and schoolID)\n",
    "### Write them to players_with_multiple_ids.csv so they can be consolidated in the match files or ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53a5afc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PlayerID Mapping (duplicates → max ID) ===\n",
      "100525 -> 128882\n",
      "143598 -> 169128\n",
      "124185 -> 168386\n",
      "122976 -> 124727\n",
      "162497 -> 162498\n",
      "172920 -> 172923\n",
      "172921 -> 172923\n",
      "172922 -> 172923\n",
      "142431 -> 164432\n",
      "143170 -> 170256\n",
      "143167 -> 171924\n",
      "145890 -> 172536\n",
      "124836 -> 145256\n",
      "149397 -> 171518\n",
      "161963 -> 162345\n",
      "143164 -> 171912\n",
      "142662 -> 151837\n",
      "121943 -> 172535\n",
      "122814 -> 171922\n",
      "121440 -> 122799\n",
      "161965 -> 162348\n",
      "121381 -> 141693\n",
      "163455 -> 163456\n",
      "141281 -> 171591\n",
      "121069 -> 163885\n",
      "106325 -> 143050\n",
      "161989 -> 168713\n",
      "122284 -> 143338\n",
      "122806 -> 171917\n",
      "168688 -> 168697\n",
      "143165 -> 171911\n",
      "\n",
      "Mapping saved to: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\players_with_multiple_ids.csv\n"
     ]
    }
   ],
   "source": [
    "# --- File paths ---\n",
    "main_dir = r\"C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\"\n",
    "csv_path = os.path.join(main_dir, \"girls_players.csv\")\n",
    "output_path = os.path.join(main_dir, \"players_with_multiple_ids.csv\")\n",
    "\n",
    "# --- Load file ---\n",
    "df = pd.read_csv(csv_path, dtype={\"playerID\": int, \"schoolID\": int})\n",
    "\n",
    "# --- Normalize name fields (recommended) ---\n",
    "df[\"firstname\"] = df[\"firstname\"].astype(str).str.strip()\n",
    "df[\"lastname\"]  = df[\"lastname\"].astype(str).str.strip()\n",
    "\n",
    "# --- Group by firstname, lastname, schoolID ---\n",
    "group_cols = [\"firstname\", \"lastname\", \"schoolID\"]\n",
    "duplicate_groups = df.groupby(group_cols)\n",
    "\n",
    "mapping_dict = {}\n",
    "\n",
    "# --- Process each group ---\n",
    "for group_key, group_df in duplicate_groups:\n",
    "    if len(group_df) > 1:  # Only groups with duplicates\n",
    "        max_id = group_df[\"playerID\"].max()\n",
    "        for pid in group_df[\"playerID\"]:\n",
    "            if pid != max_id:\n",
    "                mapping_dict[pid] = max_id\n",
    "\n",
    "# --- Print result ---\n",
    "print(\"\\n=== PlayerID Mapping (duplicates → max ID) ===\")\n",
    "if mapping_dict:\n",
    "    for old_id, new_id in mapping_dict.items():\n",
    "        print(f\"{old_id} -> {new_id}\")\n",
    "else:\n",
    "    print(\"No players with multiple IDs detected.\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "if mapping_dict:\n",
    "    df_out = pd.DataFrame(list(mapping_dict.items()), columns=[\"old_playerID\", \"new_playerID\"])\n",
    "    df_out.to_csv(output_path, index=False)\n",
    "    print(f\"\\nMapping saved to: {output_path}\")\n",
    "else:\n",
    "    print(\"\\nNo mapping file created (no duplicates found).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6909405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
