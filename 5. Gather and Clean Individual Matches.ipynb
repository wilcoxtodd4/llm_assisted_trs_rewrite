{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b67b7ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Singles match extraction complete.\n",
      "Output written to: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\singles_matches_raw.csv\n",
      "Total singles matches extracted: 14051\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Config\n",
    "# --------------------------------------------------\n",
    "\n",
    "MAIN_DIR = r\"C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\"\n",
    "REPORT_DIR = os.path.join(MAIN_DIR, \"school_reports_2025_girls\")\n",
    "FILES_LIST = os.path.join(MAIN_DIR, \"schools_with_json_files.csv\")\n",
    "OUTPUT_CSV = os.path.join(MAIN_DIR, \"singles_matches_raw.csv\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Extract Singles Matches (safe version)\n",
    "# --------------------------------------------------\n",
    "\n",
    "def extract_singles_from_meet(meet):\n",
    "\n",
    "    # Protect against null or malformed meet objects\n",
    "    if meet is None or not isinstance(meet, dict):\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    team_match_id = meet.get(\"id\")\n",
    "\n",
    "    # Convert match date safely\n",
    "    match_date_raw = meet.get(\"meetDateTime\")\n",
    "    try:\n",
    "        match_date = pd.to_datetime(match_date_raw).date()\n",
    "    except:\n",
    "        match_date = None\n",
    "\n",
    "    matches_obj = meet.get(\"matches\", {})\n",
    "    if matches_obj is None or not isinstance(matches_obj, dict):\n",
    "        return []\n",
    "\n",
    "    singles_list = matches_obj.get(\"Singles\", [])\n",
    "    if singles_list is None or not isinstance(singles_list, list):\n",
    "        singles_list = []\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Loop through each singles match\n",
    "    # ------------------------------------------------------\n",
    "    for match in singles_list:\n",
    "\n",
    "        match_type = \"Singles\"\n",
    "        match_flight = match.get(\"flight\")\n",
    "        singles_match_id = match.get(\"id\")\n",
    "\n",
    "        match_teams = match.get(\"matchTeams\", [])\n",
    "        if match_teams is None or not isinstance(match_teams, list):\n",
    "            match_teams = []\n",
    "\n",
    "        # ==============================================================\n",
    "        #                     PLAYER 0\n",
    "        # ==============================================================\n",
    "        try:\n",
    "            p0_team = match_teams[0]\n",
    "            p0_id_in_match = p0_team.get(\"id\")\n",
    "            p0_is_winner = p0_team.get(\"isWinner\")\n",
    "\n",
    "            p0_players = p0_team.get(\"players\", [])\n",
    "            if p0_players is None:\n",
    "                p0_players = []\n",
    "\n",
    "            p0_real_id = p0_players[0].get(\"id\") if len(p0_players) > 0 else None\n",
    "\n",
    "        except:\n",
    "            p0_id_in_match = None\n",
    "            p0_is_winner = None\n",
    "            p0_real_id = None\n",
    "\n",
    "        # ==============================================================\n",
    "        #                     PLAYER 1\n",
    "        # ==============================================================\n",
    "        try:\n",
    "            p1_team = match_teams[1]\n",
    "            p1_id_in_match = p1_team.get(\"id\")\n",
    "\n",
    "            p1_players = p1_team.get(\"players\", [])\n",
    "            if p1_players is None:\n",
    "                p1_players = []\n",
    "\n",
    "            p1_real_id = p1_players[0].get(\"id\") if len(p1_players) > 0 else None\n",
    "\n",
    "        except:\n",
    "            p1_id_in_match = None\n",
    "            p1_real_id = None\n",
    "\n",
    "        # ==============================================================\n",
    "        #                     SET SCORES\n",
    "        # ==============================================================\n",
    "        sets = match.get(\"sets\", [])\n",
    "        if sets is None or not isinstance(sets, list):\n",
    "            sets = []\n",
    "\n",
    "        set_scores = [None, None, None]  # set1, set2, set3\n",
    "\n",
    "        p0_key = str(p0_id_in_match) if p0_id_in_match is not None else None\n",
    "        p1_key = str(p1_id_in_match) if p1_id_in_match is not None else None\n",
    "\n",
    "        for idx, s in enumerate(sets):\n",
    "            if idx > 2:\n",
    "                break\n",
    "            try:\n",
    "                p0_score = s.get(p0_key)\n",
    "                p1_score = s.get(p1_key)\n",
    "                if p0_score is not None and p1_score is not None:\n",
    "                    set_scores[idx] = f\"{p0_score}*{p1_score}\"\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # ==============================================================\n",
    "        #                     BUILD RESULT ROW\n",
    "        # ==============================================================\n",
    "        results.append({\n",
    "            \"team_match_id\": team_match_id,\n",
    "            \"match_date\": match_date,\n",
    "            \"match_type\": match_type,\n",
    "            \"match_flight\": match_flight,\n",
    "            \"singles_match_id\": singles_match_id,\n",
    "            \"singles_player0_id_in_match\": p0_id_in_match,\n",
    "            \"singles_player0_is_winner\": p0_is_winner,\n",
    "            \"singles_player0_real_id\": p0_real_id,\n",
    "            \"singles_player1_id_in_match\": p1_id_in_match,\n",
    "            \"singles_player1_real_id\": p1_real_id,\n",
    "            \"set1_score\": set_scores[0],\n",
    "            \"set2_score\": set_scores[1],\n",
    "            \"set3_score\": set_scores[2]\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Main program (safe version)\n",
    "# --------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    df_files = pd.read_csv(FILES_LIST)\n",
    "\n",
    "    # Full run\n",
    "    filenames = df_files[\"filename\"].tolist()\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        full_path = os.path.join(REPORT_DIR, filename)\n",
    "\n",
    "        if not os.path.exists(full_path):\n",
    "            print(f\"Missing file: {full_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load JSON safely\n",
    "        try:\n",
    "            with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading JSON {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # ------------------------------------------------------\n",
    "        # FIX: Normalize meets into a list\n",
    "        # ------------------------------------------------------\n",
    "        meets = data.get(\"meets\")\n",
    "        if not isinstance(meets, list):\n",
    "            meets = []\n",
    "\n",
    "        for meet in meets:\n",
    "            rows = extract_singles_from_meet(meet)\n",
    "            if rows:\n",
    "                all_rows.extend(rows)\n",
    "\n",
    "    df_out = pd.DataFrame(all_rows)\n",
    "    df_out.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\nSingles match extraction complete.\")\n",
    "    print(f\"Output written to: {OUTPUT_CSV}\")\n",
    "    print(f\"Total singles matches extracted: {len(df_out)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c511a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02d35a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file list from: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\schools_with_json_files.csv\n",
      "\n",
      "Doubles match extraction complete.\n",
      "File written: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\doubles_matches_raw.csv\n",
      "Total doubles matches extracted: 13663\n"
     ]
    }
   ],
   "source": [
    "MAIN_DIR = r\"C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\"\n",
    "REPORT_DIR = os.path.join(MAIN_DIR, \"school_reports_2025_girls\")\n",
    "FILES_LIST = os.path.join(MAIN_DIR, \"schools_with_json_files.csv\")\n",
    "OUTPUT_CSV = os.path.join(MAIN_DIR, \"doubles_matches_raw.csv\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Extract Doubles Matches (with set scores)\n",
    "# --------------------------------------------------\n",
    "\n",
    "def extract_doubles_from_meet(meet):\n",
    "\n",
    "    # Protect against malformed meet entries\n",
    "    if meet is None or not isinstance(meet, dict):\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    team_match_id = meet.get(\"id\")\n",
    "\n",
    "    # Convert match date safely\n",
    "    match_date_raw = meet.get(\"meetDateTime\")\n",
    "    try:\n",
    "        match_date = pd.to_datetime(match_date_raw).date()\n",
    "    except:\n",
    "        match_date = None\n",
    "\n",
    "    matches_obj = meet.get(\"matches\", {})\n",
    "    if matches_obj is None or not isinstance(matches_obj, dict):\n",
    "        return []\n",
    "\n",
    "    doubles_list = matches_obj.get(\"Doubles\", [])\n",
    "    if doubles_list is None or not isinstance(doubles_list, list):\n",
    "        doubles_list = []\n",
    "\n",
    "    for match in doubles_list:\n",
    "\n",
    "        match_type = \"Doubles\"\n",
    "        match_flight = match.get(\"flight\")\n",
    "        doubles_match_id = match.get(\"id\")\n",
    "\n",
    "        match_teams = match.get(\"matchTeams\", [])\n",
    "        if match_teams is None or not isinstance(match_teams, list):\n",
    "            match_teams = []\n",
    "\n",
    "        # ==============================================================\n",
    "        #             TEAM 0  (Players 1 & 2)\n",
    "        # ==============================================================\n",
    "\n",
    "        try:\n",
    "            t0_team = match_teams[0]\n",
    "            t0_id_in_match = t0_team.get(\"id\")\n",
    "            t0_is_winner = t0_team.get(\"isWinner\")\n",
    "\n",
    "            t0_players = t0_team.get(\"players\", [])\n",
    "            if t0_players is None:\n",
    "                t0_players = []\n",
    "\n",
    "            t0_p1_real = t0_players[0].get(\"id\") if len(t0_players) > 0 else None\n",
    "            t0_p2_real = t0_players[1].get(\"id\") if len(t0_players) > 1 else None\n",
    "\n",
    "        except:\n",
    "            t0_id_in_match = None\n",
    "            t0_is_winner = None\n",
    "            t0_p1_real = None\n",
    "            t0_p2_real = None\n",
    "\n",
    "        # ==============================================================\n",
    "        #             TEAM 1  (Players 3 & 4)\n",
    "        # ==============================================================\n",
    "\n",
    "        try:\n",
    "            t1_team = match_teams[1]\n",
    "            t1_id_in_match = t1_team.get(\"id\")\n",
    "\n",
    "            t1_players = t1_team.get(\"players\", [])\n",
    "            if t1_players is None:\n",
    "                t1_players = []\n",
    "\n",
    "            t1_p1_real = t1_players[0].get(\"id\") if len(t1_players) > 0 else None\n",
    "            t1_p2_real = t1_players[1].get(\"id\") if len(t1_players) > 1 else None\n",
    "\n",
    "        except:\n",
    "            t1_id_in_match = None\n",
    "            t1_p1_real = None\n",
    "            t1_p2_real = None\n",
    "\n",
    "        # ==============================================================\n",
    "        #                     SET SCORES\n",
    "        # ==============================================================\n",
    "\n",
    "        sets = match.get(\"sets\", [])\n",
    "        if sets is None or not isinstance(sets, list):\n",
    "            sets = []\n",
    "\n",
    "        set_scores = [None, None, None]\n",
    "\n",
    "        t0_key = str(t0_id_in_match) if t0_id_in_match is not None else None\n",
    "        t1_key = str(t1_id_in_match) if t1_id_in_match is not None else None\n",
    "\n",
    "        for idx, s in enumerate(sets):\n",
    "            if idx > 2:\n",
    "                break\n",
    "            try:\n",
    "                t0_score = s.get(t0_key)\n",
    "                t1_score = s.get(t1_key)\n",
    "\n",
    "                if t0_score is not None and t1_score is not None:\n",
    "                    set_scores[idx] = f\"{t0_score}*{t1_score}\"\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # ==============================================================\n",
    "\n",
    "        results.append({\n",
    "            \"team_match_id\": team_match_id,\n",
    "            \"match_date\": match_date,\n",
    "            \"match_type\": match_type,\n",
    "            \"match_flight\": match_flight,\n",
    "            \"doubles_match_id\": doubles_match_id,\n",
    "\n",
    "            # Team 0 player info\n",
    "            \"doubles_team0_id_in_match\": t0_id_in_match,\n",
    "            \"doubles_team0_is_winner\": t0_is_winner,\n",
    "            \"doubles_team0_player1_real_id\": t0_p1_real,\n",
    "            \"doubles_team0_player2_real_id\": t0_p2_real,\n",
    "\n",
    "            # Team 1 player info\n",
    "            \"doubles_team1_id_in_match\": t1_id_in_match,\n",
    "            \"doubles_team1_player1_real_id\": t1_p1_real,\n",
    "            \"doubles_team1_player2_real_id\": t1_p2_real,\n",
    "\n",
    "            # Set scores\n",
    "            \"set1_score\": set_scores[0],\n",
    "            \"set2_score\": set_scores[1],\n",
    "            \"set3_score\": set_scores[2]\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Main Program\n",
    "# --------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading file list from: {FILES_LIST}\")\n",
    "    df_files = pd.read_csv(FILES_LIST)\n",
    "\n",
    "    # Process ALL files (remove .head(5) for full run)\n",
    "    file_list = df_files[\"filename\"].tolist()\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for filename in file_list:\n",
    "        full_path = os.path.join(REPORT_DIR, filename)\n",
    "\n",
    "        if not os.path.exists(full_path):\n",
    "            print(f\"Missing file: {full_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------\n",
    "        # FIX: normalize meets\n",
    "        # -----------------------\n",
    "        meets = data.get(\"meets\")\n",
    "        if not isinstance(meets, list):\n",
    "            meets = []\n",
    "\n",
    "        for meet in meets:\n",
    "            rows = extract_doubles_from_meet(meet)\n",
    "            if rows:\n",
    "                all_rows.extend(rows)\n",
    "\n",
    "    df_out = pd.DataFrame(all_rows)\n",
    "    df_out.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\nDoubles match extraction complete.\")\n",
    "    print(f\"File written: {OUTPUT_CSV}\")\n",
    "    print(f\"Total doubles matches extracted: {len(df_out)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651ee0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ac7da89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned singles matches written to: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\singles_matches_cleaner.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Config\n",
    "# --------------------------------------------------\n",
    "\n",
    "MAIN_DIR = r\"C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\"\n",
    "INPUT_FILE = os.path.join(MAIN_DIR, \"singles_matches_raw.csv\")\n",
    "OUTPUT_FILE = os.path.join(MAIN_DIR, \"singles_matches_cleaner.csv\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Helper to reverse scores \"3*6\" → \"6*3\"\n",
    "# --------------------------------------------------\n",
    "def reverse_score(score):\n",
    "    if pd.isna(score) or score is None:\n",
    "        return None\n",
    "    try:\n",
    "        a, b = score.split(\"*\")\n",
    "        return f\"{b}*{a}\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Main cleaning process\n",
    "# --------------------------------------------------\n",
    "\n",
    "def main():\n",
    "\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Create new field: flight = S + match_flight\n",
    "    # --------------------------------------------------\n",
    "    df[\"flight\"] = \"S\" + df[\"match_flight\"].astype(str)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Create winner1 and loser1\n",
    "    # --------------------------------------------------\n",
    "    df[\"winner1\"] = df.apply(\n",
    "        lambda row: row[\"singles_player0_real_id\"]\n",
    "        if row[\"singles_player0_is_winner\"] == True\n",
    "        else row[\"singles_player1_real_id\"],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df[\"loser1\"] = df.apply(\n",
    "        lambda row: row[\"singles_player0_real_id\"]\n",
    "        if row[\"singles_player0_is_winner\"] == False\n",
    "        else row[\"singles_player1_real_id\"],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Build set1, set2, set3 (with reversing)\n",
    "    # --------------------------------------------------\n",
    "    def choose_score(row, col):\n",
    "        \"\"\"Return the correct orientation of the set score.\"\"\"\n",
    "        score = row[col]\n",
    "        if row[\"singles_player0_is_winner\"] == True:\n",
    "            return score\n",
    "        else:\n",
    "            return reverse_score(score)\n",
    "\n",
    "    df[\"set1\"] = df.apply(lambda r: choose_score(r, \"set1_score\"), axis=1)\n",
    "    df[\"set2\"] = df.apply(lambda r: choose_score(r, \"set2_score\"), axis=1)\n",
    "    df[\"set3\"] = df.apply(lambda r: choose_score(r, \"set3_score\"), axis=1)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Drop unwanted columns\n",
    "    # --------------------------------------------------\n",
    "    df = df.drop(columns=[\n",
    "        \"match_type\",\n",
    "        \"singles_player0_id_in_match\",\n",
    "        \"singles_player1_id_in_match\",\n",
    "        \"singles_player0_real_id\",\n",
    "        \"singles_player1_real_id\",\n",
    "        \"set1_score\",\n",
    "        \"set2_score\",\n",
    "        \"set3_score\",\n",
    "        \"singles_player0_is_winner\",\n",
    "        \"match_flight\"\n",
    "    ], errors=\"ignore\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Drop records where set1_score == '2*0'\n",
    "    # --------------------------------------------------\n",
    "    df = df[df[\"set1\"] != \"2*0\"]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Drop records where all three sets are null\n",
    "    # --------------------------------------------------\n",
    "    df = df[~(df[\"set1\"].isna() & df[\"set2\"].isna() & df[\"set3\"].isna())]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Shift sets upward if earlier ones are blank\n",
    "    # --------------------------------------------------\n",
    "    def shift_sets(row):\n",
    "        sets = [row[\"set1\"], row[\"set2\"], row[\"set3\"]]\n",
    "        # Remove None values but keep order\n",
    "        non_null = [s for s in sets if pd.notna(s)]\n",
    "\n",
    "        # Pad with None back to length 3\n",
    "        non_null += [None] * (3 - len(non_null))\n",
    "\n",
    "        return pd.Series({\n",
    "            \"set1\": non_null[0],\n",
    "            \"set2\": non_null[1],\n",
    "            \"set3\": non_null[2]\n",
    "        })\n",
    "\n",
    "    df[[\"set1\", \"set2\", \"set3\"]] = df.apply(shift_sets, axis=1)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Replace any remaining nulls with \"0*0\"\n",
    "    # --------------------------------------------------\n",
    "    df[\"set1\"] = df[\"set1\"].fillna(\"0*0\")\n",
    "    df[\"set2\"] = df[\"set2\"].fillna(\"0*0\")\n",
    "    df[\"set3\"] = df[\"set3\"].fillna(\"0*0\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Write output\n",
    "    # --------------------------------------------------\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Cleaned singles matches written to: {OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc83c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "167acc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubles matches cleaned → C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\doubles_matches_cleaner.csv\n"
     ]
    }
   ],
   "source": [
    "MAIN_DIR = r\"C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\"\n",
    "INPUT_FILE = os.path.join(MAIN_DIR, \"doubles_matches_raw.csv\")\n",
    "OUTPUT_FILE = os.path.join(MAIN_DIR, \"doubles_matches_cleaner.csv\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Helper to reverse scores \"3*6\" → \"6*3\"\n",
    "# --------------------------------------------------\n",
    "def reverse_score(score):\n",
    "    if pd.isna(score) or score is None:\n",
    "        return None\n",
    "    try:\n",
    "        a, b = score.split(\"*\")\n",
    "        return f\"{b}*{a}\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Main cleaning process\n",
    "# --------------------------------------------------\n",
    "\n",
    "def main():\n",
    "\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Create new field: flight = D + match_flight\n",
    "    # --------------------------------------------------\n",
    "    df[\"flight\"] = \"D\" + df[\"match_flight\"].astype(str)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Create winners & losers\n",
    "    # team0 is winner if doubles_team0_is_winner == TRUE\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    df[\"winner1\"] = df.apply(\n",
    "        lambda r: r[\"doubles_team0_player1_real_id\"]\n",
    "        if r[\"doubles_team0_is_winner\"] == True\n",
    "        else r[\"doubles_team1_player1_real_id\"],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df[\"winner2\"] = df.apply(\n",
    "        lambda r: r[\"doubles_team0_player2_real_id\"]\n",
    "        if r[\"doubles_team0_is_winner\"] == True\n",
    "        else r[\"doubles_team1_player2_real_id\"],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df[\"loser1\"] = df.apply(\n",
    "        lambda r: r[\"doubles_team0_player1_real_id\"]\n",
    "        if r[\"doubles_team0_is_winner\"] == False\n",
    "        else r[\"doubles_team1_player1_real_id\"],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df[\"loser2\"] = df.apply(\n",
    "        lambda r: r[\"doubles_team0_player2_real_id\"]\n",
    "        if r[\"doubles_team0_is_winner\"] == False\n",
    "        else r[\"doubles_team1_player2_real_id\"],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Build set1, set2, set3 (with reversing)\n",
    "    # --------------------------------------------------\n",
    "    def choose_score(row, col):\n",
    "        score = row[col]\n",
    "        if row[\"doubles_team0_is_winner\"] == True:\n",
    "            return score\n",
    "        else:\n",
    "            return reverse_score(score)\n",
    "\n",
    "    df[\"set1\"] = df.apply(lambda r: choose_score(r, \"set1_score\"), axis=1)\n",
    "    df[\"set2\"] = df.apply(lambda r: choose_score(r, \"set2_score\"), axis=1)\n",
    "    df[\"set3\"] = df.apply(lambda r: choose_score(r, \"set3_score\"), axis=1)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Drop unwanted fields\n",
    "    # --------------------------------------------------\n",
    "    df = df.drop(columns=[\n",
    "        \"match_type\",\n",
    "        \"doubles_team0_id_in_match\",\n",
    "        \"doubles_team1_id_in_match\",\n",
    "        \"doubles_team0_player1_real_id\",\n",
    "        \"doubles_team0_player2_real_id\",\n",
    "        \"doubles_team1_player1_real_id\",\n",
    "        \"doubles_team1_player2_real_id\",\n",
    "        \"set1_score\",\n",
    "        \"set2_score\",\n",
    "        \"set3_score\",\n",
    "        \"doubles_team0_is_winner\",\n",
    "        \"match_flight\"\n",
    "    ], errors=\"ignore\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Drop records where set1 = “2*0”\n",
    "    # --------------------------------------------------\n",
    "    df = df[df[\"set1\"] != \"2*0\"]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Drop records where all 3 sets are null\n",
    "    # --------------------------------------------------\n",
    "    df = df[~(df[\"set1\"].isna() & df[\"set2\"].isna() & df[\"set3\"].isna())]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Shift sets upward if needed\n",
    "    # --------------------------------------------------\n",
    "    def shift_sets(row):\n",
    "        sets = [row[\"set1\"], row[\"set2\"], row[\"set3\"]]\n",
    "        non_null = [s for s in sets if pd.notna(s)]\n",
    "        non_null += [None] * (3 - len(non_null))\n",
    "        return pd.Series({\n",
    "            \"set1\": non_null[0],\n",
    "            \"set2\": non_null[1],\n",
    "            \"set3\": non_null[2]\n",
    "        })\n",
    "\n",
    "    df[[\"set1\", \"set2\", \"set3\"]] = df.apply(shift_sets, axis=1)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Replace any remaining nulls with “0*0”\n",
    "    # --------------------------------------------------\n",
    "    df[\"set1\"] = df[\"set1\"].fillna(\"0*0\")\n",
    "    df[\"set2\"] = df[\"set2\"].fillna(\"0*0\")\n",
    "    df[\"set3\"] = df[\"set3\"].fillna(\"0*0\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Save output\n",
    "    # --------------------------------------------------\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Doubles matches cleaned → {OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f146a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32fd983c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaner2 generation complete.\n",
      "Singles written to: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\singles_cleaner2.csv\n",
      "Doubles written to: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\doubles_cleaner2.csv\n",
      "Transformation logs written to C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\singles_score_transformations.csv and C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\doubles_score_transformations.csv\n"
     ]
    }
   ],
   "source": [
    "MAIN_DIR = r\"C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\"\n",
    "\n",
    "SINGLES_INPUT  = MAIN_DIR + r\"\\singles_matches_cleaner.csv\"\n",
    "DOUBLES_INPUT  = MAIN_DIR + r\"\\doubles_matches_cleaner.csv\"\n",
    "\n",
    "SINGLES_OUTPUT = MAIN_DIR + r\"\\singles_cleaner2.csv\"\n",
    "DOUBLES_OUTPUT = MAIN_DIR + r\"\\doubles_cleaner2.csv\"\n",
    "\n",
    "SINGLES_TRANS  = MAIN_DIR + r\"\\singles_score_transformations.csv\"\n",
    "DOUBLES_TRANS  = MAIN_DIR + r\"\\doubles_score_transformations.csv\"\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Helper functions\n",
    "# --------------------------------------------------\n",
    "\n",
    "def parse_score(s):\n",
    "    try:\n",
    "        a, b = s.split(\"*\")\n",
    "        return int(a), int(b)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def total_games(row):\n",
    "    tot = 0\n",
    "    for col in [\"set1\", \"set2\", \"set3\"]:\n",
    "        sc = parse_score(str(row[col]))\n",
    "        if sc:\n",
    "            tot += sc[0] + sc[1]\n",
    "    return tot\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- RULE 3 (UPDATED): fix 60–76 values ----------------\n",
    "\n",
    "def fix_large_values(s):\n",
    "    sc = parse_score(str(s))\n",
    "    if not sc:\n",
    "        return s\n",
    "\n",
    "    a, b = sc\n",
    "\n",
    "    # Apply to 60–76 on EITHER side\n",
    "    if 60 <= a <= 76:\n",
    "        a_new = int(str(a)[0])\n",
    "        b_new = int(str(a)[1])\n",
    "        return f\"{a_new}*{b_new}\"\n",
    "\n",
    "    if 60 <= b <= 76:\n",
    "        a_new = int(str(b)[1])\n",
    "        b_new = int(str(b)[0])\n",
    "        return f\"{a_new}*{b_new}\"\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- RULE 4 (UPDATED): Set3 big values ----------------\n",
    "\n",
    "def fix_set3_big(s):\n",
    "    sc = parse_score(str(s))\n",
    "    if not sc:\n",
    "        return s\n",
    "\n",
    "    a, b = sc\n",
    "    if a >= 10 or b >= 10:\n",
    "        # If a > b, winner is left → return 1*0\n",
    "        if a > b:\n",
    "            return \"1*0\"\n",
    "        else:\n",
    "            return \"0*1\"\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- RULE 6 (NEW): Large values for sets 1–2 ----------------\n",
    "\n",
    "def fix_big_set_1_2(s):\n",
    "    sc = parse_score(str(s))\n",
    "    if not sc:\n",
    "        return s\n",
    "\n",
    "    a, b = sc\n",
    "\n",
    "    if a >= 10 or b >= 10:\n",
    "        if a > b:\n",
    "            return \"7*6\"   # winner on left\n",
    "        else:\n",
    "            return \"6*7\"   # winner on right\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- RULE 7 (NEW): 7*0–7*4 and 0*7–4*7 ----------------\n",
    "\n",
    "def fix_7x_low(s):\n",
    "    sc = parse_score(str(s))\n",
    "    if not sc:\n",
    "        return s\n",
    "\n",
    "    a, b = sc\n",
    "\n",
    "    # 7 beating low scores\n",
    "    if a == 7 and b in [0,1,2,3,4]:\n",
    "        return \"7*6\"\n",
    "\n",
    "    # losing to 7\n",
    "    if b == 7 and a in [0,1,2,3,4]:\n",
    "        return \"6*7\"\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Main processing function\n",
    "# --------------------------------------------------\n",
    "\n",
    "def process(df, idcol, transfile):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Drop low-total-game rows\n",
    "    df[\"tg\"] = df.apply(total_games, axis=1)\n",
    "    df = df[df.tg >= 6].drop(columns=[\"tg\"])\n",
    "\n",
    "    # 2) Reverse entire match if last valid set is backwards\n",
    "    for idx, row in df.iterrows():\n",
    "        for col in [\"set3\", \"set2\", \"set1\"]:\n",
    "            sc = parse_score(str(row[col]))\n",
    "            if sc:\n",
    "                if sc[0] < sc[1]:\n",
    "                    # reverse all sets\n",
    "                    for c in [\"set1\", \"set2\", \"set3\"]:\n",
    "                        s = parse_score(str(row[c]))\n",
    "                        if s:\n",
    "                            df.at[idx, c] = f\"{s[1]}*{s[0]}\"\n",
    "                break\n",
    "\n",
    "    # 3–7) Transformations WITH LOGGING\n",
    "    logs = []\n",
    "\n",
    "    # ---- Rule 3\n",
    "    for idx, row in df.iterrows():\n",
    "        for col in [\"set1\", \"set2\", \"set3\"]:\n",
    "            orig = row[col]\n",
    "            new  = fix_large_values(orig)\n",
    "            if new != orig:\n",
    "                logs.append([row[idcol], col, orig, new])\n",
    "                df.at[idx, col] = new\n",
    "\n",
    "    # ---- Rule 4 (set3 only)\n",
    "    for idx, row in df.iterrows():\n",
    "        col = \"set3\"\n",
    "        orig = row[col]\n",
    "        new  = fix_set3_big(orig)\n",
    "        if new != orig:\n",
    "            logs.append([row[idcol], col, orig, new])\n",
    "            df.at[idx, col] = new\n",
    "\n",
    "    # ---- Rule 6 (sets 1 and 2)\n",
    "    for idx, row in df.iterrows():\n",
    "        for col in [\"set1\", \"set2\"]:\n",
    "            orig = row[col]\n",
    "            new  = fix_big_set_1_2(orig)\n",
    "            if new != orig:\n",
    "                logs.append([row[idcol], col, orig, new])\n",
    "                df.at[idx, col] = new\n",
    "\n",
    "    # ---- Rule 7\n",
    "    for idx, row in df.iterrows():\n",
    "        for col in [\"set1\", \"set2\", \"set3\"]:\n",
    "            orig = row[col]\n",
    "            new  = fix_7x_low(orig)\n",
    "            if new != orig:\n",
    "                logs.append([row[idcol], col, orig, new])\n",
    "                df.at[idx, col] = new\n",
    "\n",
    "    # Save transformation log\n",
    "    tf = pd.DataFrame(logs, columns=[\"match_id\", \"set\", \"before\", \"after\"])\n",
    "    tf.to_csv(transfile, index=False)\n",
    "\n",
    "    return df, tf\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Apply to singles and doubles\n",
    "# --------------------------------------------------\n",
    "\n",
    "df_sing = pd.read_csv(SINGLES_INPUT)\n",
    "df_doub = pd.read_csv(DOUBLES_INPUT)\n",
    "\n",
    "sing2, t1 = process(df_sing, \"singles_match_id\", SINGLES_TRANS)\n",
    "doub2, t2 = process(df_doub, \"doubles_match_id\", DOUBLES_TRANS)\n",
    "\n",
    "sing2.to_csv(SINGLES_OUTPUT, index=False)\n",
    "doub2.to_csv(DOUBLES_OUTPUT, index=False)\n",
    "\n",
    "print(\"Cleaner2 generation complete.\")\n",
    "print(f\"Singles written to: {SINGLES_OUTPUT}\")\n",
    "print(f\"Doubles written to: {DOUBLES_OUTPUT}\")\n",
    "print(f\"Transformation logs written to {SINGLES_TRANS} and {DOUBLES_TRANS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daaee2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Frequency Report for Singles Cleaner 2\n",
      "==============================\n",
      "\n",
      "--- set1 Frequencies ---\n",
      "set1\n",
      "0*6      78\n",
      "0*8       8\n",
      "1*0       2\n",
      "1*6     161\n",
      "1*8       5\n",
      "2*4       1\n",
      "2*6     193\n",
      "2*8       4\n",
      "3*6     178\n",
      "3*8       3\n",
      "4*0      19\n",
      "4*1       6\n",
      "4*2       6\n",
      "4*3       5\n",
      "4*6     255\n",
      "4*8      16\n",
      "5*1       2\n",
      "5*7     120\n",
      "5*8       2\n",
      "6*0    3514\n",
      "6*1    2203\n",
      "6*2    1370\n",
      "6*3    1367\n",
      "6*4     956\n",
      "6*5       2\n",
      "6*6       4\n",
      "6*7     108\n",
      "7*5     371\n",
      "7*6     278\n",
      "7*9       4\n",
      "8*0     491\n",
      "8*1     489\n",
      "8*2     374\n",
      "8*3     240\n",
      "8*4     383\n",
      "8*5     258\n",
      "8*6     167\n",
      "8*7      30\n",
      "8*8       2\n",
      "8*9       4\n",
      "9*7      81\n",
      "9*8      41\n",
      "\n",
      "--- set2 Frequencies ---\n",
      "set2\n",
      "0*0    2643\n",
      "0*1       6\n",
      "0*4       1\n",
      "0*6      97\n",
      "1*0       8\n",
      "1*1       2\n",
      "1*6     117\n",
      "2*1       2\n",
      "2*4       2\n",
      "2*6      94\n",
      "3*0       4\n",
      "3*2       2\n",
      "3*4       3\n",
      "3*5       2\n",
      "3*6     172\n",
      "4*0      16\n",
      "4*1       8\n",
      "4*2       7\n",
      "4*3      17\n",
      "4*6     188\n",
      "5*2       2\n",
      "5*5       2\n",
      "5*7      76\n",
      "6*0    3554\n",
      "6*1    2084\n",
      "6*2    1816\n",
      "6*3    1138\n",
      "6*4    1052\n",
      "6*6       4\n",
      "6*7      64\n",
      "7*5     253\n",
      "7*6     363\n",
      "7*9       2\n",
      "\n",
      "--- set3 Frequencies ---\n",
      "set3\n",
      "0*0    12320\n",
      "1*0      599\n",
      "5*1        2\n",
      "6*0       68\n",
      "6*1       93\n",
      "6*2      179\n",
      "6*3      183\n",
      "6*4      210\n",
      "7*5       80\n",
      "7*6       66\n",
      "9*7        1\n",
      "\n",
      "==============================\n",
      " Frequency Report for Doubles Cleaner 2\n",
      "==============================\n",
      "\n",
      "--- set1 Frequencies ---\n",
      "set1\n",
      "0*1       4\n",
      "0*6      70\n",
      "0*8       6\n",
      "1*0       4\n",
      "1*4       1\n",
      "1*6     147\n",
      "1*8       4\n",
      "2*4       2\n",
      "2*6     164\n",
      "2*8       9\n",
      "3*4       4\n",
      "3*6     206\n",
      "3*8      10\n",
      "4*0       9\n",
      "4*1       9\n",
      "4*2       6\n",
      "4*3       2\n",
      "4*6     260\n",
      "4*8       2\n",
      "5*1       2\n",
      "5*7     165\n",
      "5*8       2\n",
      "6*0    2246\n",
      "6*1    2321\n",
      "6*2    1762\n",
      "6*3    1658\n",
      "6*4    1154\n",
      "6*7     152\n",
      "6*8       2\n",
      "7*5     480\n",
      "7*6     364\n",
      "8*0     277\n",
      "8*1     348\n",
      "8*2     418\n",
      "8*3     352\n",
      "8*4     417\n",
      "8*5     127\n",
      "8*6     168\n",
      "8*7       2\n",
      "8*8      13\n",
      "9*7      69\n",
      "9*8      51\n",
      "\n",
      "--- set2 Frequencies ---\n",
      "set2\n",
      "0*0    2331\n",
      "0*1       4\n",
      "0*6     110\n",
      "1*0       2\n",
      "1*4       2\n",
      "1*6     108\n",
      "2*0       2\n",
      "2*1       2\n",
      "2*6     196\n",
      "3*1       4\n",
      "3*2       4\n",
      "3*4       2\n",
      "3*6     188\n",
      "4*0       6\n",
      "4*1       3\n",
      "4*2       6\n",
      "4*3       8\n",
      "4*6     260\n",
      "5*0       2\n",
      "5*7     163\n",
      "6*0    2329\n",
      "6*1    2339\n",
      "6*2    1736\n",
      "6*3    1368\n",
      "6*4    1255\n",
      "6*5       2\n",
      "6*6      11\n",
      "6*7      99\n",
      "7*5     560\n",
      "7*6     365\n",
      "8*8       2\n",
      "\n",
      "--- set3 Frequencies ---\n",
      "set3\n",
      "0*0    11569\n",
      "1*0      746\n",
      "6*0       70\n",
      "6*1      158\n",
      "6*2      186\n",
      "6*3      161\n",
      "6*4      324\n",
      "7*5      109\n",
      "7*6      146\n"
     ]
    }
   ],
   "source": [
    "BASE = r\"C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\"\n",
    "\n",
    "singles_file = BASE + r\"\\singles_cleaner2.csv\"\n",
    "doubles_file = BASE + r\"\\doubles_cleaner2.csv\"\n",
    "\n",
    "# Load files\n",
    "df_sing = pd.read_csv(singles_file)\n",
    "df_doub = pd.read_csv(doubles_file)\n",
    "\n",
    "def audit_set_frequencies(df, label):\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" Frequency Report for {label}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    for col in [\"set1\", \"set2\", \"set3\"]:\n",
    "        print(f\"\\n--- {col} Frequencies ---\")\n",
    "        freq = df[col].value_counts(dropna=False).sort_index()\n",
    "        print(freq.to_string())\n",
    "\n",
    "# Run audits\n",
    "audit_set_frequencies(df_sing, \"Singles Cleaner 2\")\n",
    "audit_set_frequencies(df_doub, \"Doubles Cleaner 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9799563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\singles_cleaner2.csv\n",
      "  Records before dedupe: 13801\n",
      "  Records after  dedupe: 4107\n",
      "  Duplicates removed:    9694\n",
      "  Clean file written to: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\singles_matches_clean.csv\n",
      "\n",
      "Processing: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\doubles_cleaner2.csv\n",
      "  Records before dedupe: 13469\n",
      "  Records after  dedupe: 4024\n",
      "  Duplicates removed:    9445\n",
      "  Clean file written to: C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\\doubles_matches_clean.csv\n",
      "\n",
      "All clean files generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MAIN_DIR = r\"C:\\Users\\toddw\\Desktop\\Python Rating Code and Files\\GenAI_Rewrite\"\n",
    "\n",
    "# Input files\n",
    "SINGLES_IN  = MAIN_DIR + r\"\\singles_cleaner2.csv\"\n",
    "DOUBLES_IN  = MAIN_DIR + r\"\\doubles_cleaner2.csv\"\n",
    "\n",
    "# Output files\n",
    "SINGLES_OUT = MAIN_DIR + r\"\\singles_matches_clean.csv\"\n",
    "DOUBLES_OUT = MAIN_DIR + r\"\\doubles_matches_clean.csv\"\n",
    "\n",
    "\n",
    "def dedupe_file(input_csv, output_csv):\n",
    "    print(f\"\\nProcessing: {input_csv}\")\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    after = len(df)\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"  Records before dedupe: {before}\")\n",
    "    print(f\"  Records after  dedupe: {after}\")\n",
    "    print(f\"  Duplicates removed:    {before - after}\")\n",
    "    print(f\"  Clean file written to: {output_csv}\")\n",
    "\n",
    "\n",
    "# Run the dedupe operations\n",
    "dedupe_file(SINGLES_IN, SINGLES_OUT)\n",
    "dedupe_file(DOUBLES_IN, DOUBLES_OUT)\n",
    "\n",
    "print(\"\\nAll clean files generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7984ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
